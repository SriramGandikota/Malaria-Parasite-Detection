{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Malaria Parasite Detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nThe expected directory structure for the given images for running a deep network is \\n    --Current folder \\n            -- data \\n                  |\\n                  | --Parasite\\n                       |\\n                       | --- train\\n                       |     |\\n                       |     | -----Uninfected\\n                       |     | ------Parasitized\\n                       |------test\\n '"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "The expected directory structure for the given images for running a deep network is \n",
    "    --Current folder \n",
    "            -- data \n",
    "                  |\n",
    "                  | --Parasite\n",
    "                       |\n",
    "                       | --- train\n",
    "                       |     |\n",
    "                       |     | -----Uninfected\n",
    "                       |     | ------Parasitized\n",
    "                       |------test\n",
    " '''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing required libraries\n",
    "import os\n",
    "import cv2\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tqdm import tqdm\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import datetime as now\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#required helper functions\n",
    "\n",
    "#Function to get the distance from the dark pink value which also considers the brightness\n",
    "def dist(RGB):\n",
    "    return ((RGB[0]-255)**2 + (RGB[1]-20)**2 + (RGB[2]-147)**2)**0.5\n",
    "#Calculating the maximum varance and distance for a given (i,j) pixel\n",
    "def neighbor_var(img,i,j):\n",
    "    ans = -1\n",
    "    x = [1,0,-1]\n",
    "    y = [1,0,-1]\n",
    "    for a in x:\n",
    "        for b in y:\n",
    "            if(i+a<img.shape[0] and j+b<img.shape[1] and (a!=0 or b!=0)):\n",
    "                if(img[i+a][j+b][0]!=0 or img[i+a][j+b][1]!=0 or img[i+a][j+b][2]!=0):\n",
    "                    ans = max(ans,\n",
    "                    ((img[i][j][0]-img[i+a][j+b][0])**2 + (img[i][j][1]-img[i+a][j+b][1])**2 + (img[i][j][2]-img[i+a][j+b][2])**2)**0.5)\n",
    "    return ans\n",
    "#Accuracy Score\n",
    "def calc_acc(predict,original):\n",
    "    count = 0\n",
    "    for i in range(len(predict)):\n",
    "        if(predict[i]==original[i]):\n",
    "            count+=1\n",
    "    return (count+0.0)/(0.0+len(predict))\n",
    "def true_positive(predict,original):\n",
    "    count = 0\n",
    "    count1 = 0\n",
    "    for i in range(len(predict)):\n",
    "        if(predict[i]!=original[i]):\n",
    "            count+=1\n",
    "        if(predict[i]==0 and original[i]==1):\n",
    "            count1+=1\n",
    "    return (count1+0.0)/(count+0.0)\n",
    "#Gets the area of two largest contours \n",
    "def getContours(img):\n",
    "    imgray = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n",
    "    ret, thresh = cv2.threshold(imgray, 125, 255, 0)\n",
    "    contours,hierarchy = cv2.findContours(thresh,cv2.RETR_CCOMP,cv2.CHAIN_APPROX_SIMPLE)#cv2.CHAIN_APPROX_TC89_KCOS)\n",
    "    p = []\n",
    "    for contour in contours:\n",
    "        p.append(cv2.contourArea(contour))\n",
    "    p.sort()\n",
    "    if(len(p)==0):\n",
    "        return (0,0)\n",
    "    if(len(p)<2):\n",
    "        return (p[-1],0)\n",
    "    return (p[-1],p[-2])\n",
    "\n",
    "def extract(img):\n",
    "    d = 3*(255**2)\n",
    "    var = 0\n",
    "    for i in range(img.shape[0]):\n",
    "        for j in range(img.shape[1]):\n",
    "            if(img[i][j][0]!=0 or img[i][j][1]!=0 or img[i][j][2]!=0):\n",
    "                d = min(d,dist(img[i][j]))\n",
    "                var = max(var,neighbor_var(img,i,j))\n",
    "    return np.asarray([d,var])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#global variables \n",
    "\n",
    "IMG_SIZE = (130,130,3) #If image requires resizing this is the size\n",
    "epochs=20 #Number of epochs for deep learning \n",
    "#Inorder to use the preprocessed data directly this variable must be kept as False\n",
    "preprocess = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting featuers related to the 'pinkess' of a pixel and its variance and using Contour area"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(preprocess):\n",
    "    infected = os.listdir(os.getcwd()+\"/Parasitized\")\n",
    "    uninfected = os.listdir(os.getcwd()+\"/Uninfected\")\n",
    "    X = []\n",
    "    Y = []\n",
    "\n",
    "    for file in tqdm(infected):\n",
    "        img  = cv2.imread(os.getcwd()+\"/Parasitized/{}\".format(file))\n",
    "        X.append(img)\n",
    "        Y.append(0)\n",
    "    for file in tqdm(uninfected):\n",
    "        img  = cv2.imread(os.getcwd()+\"/Uninfected/{}\".format(file))\n",
    "        X.append(img)\n",
    "        Y.append(1)\n",
    "    print(\"Data Preprocessing.....\")\n",
    "    for img in tqdm(X):\n",
    "        X.append(extract(img))\n",
    "    for img in tqdm(X):\n",
    "        X.append(extract(img))\n",
    "else:\n",
    "    X = np.load('variance.npy')\n",
    "    Y = np.load('variance_Y.npy')\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Training "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "if(preprocess):\n",
    "    KNN = KNeighborsClassifier(n_neighbors = 193)\n",
    "    KNN.fit(X_train,Y_train)\n",
    "else:\n",
    "    KNN = pickle.load(open(\"KNN.sav\", 'rb'))\n",
    "print(calc_acc(KNN.predict(X_test),Y_test),true_positive(KNN.predict(X_test),Y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine\n",
    "if(preprocess):\n",
    "    SVM_cla = SVC(gamma='scale')\n",
    "    SVM_cla.fit(X_train,Y_train)\n",
    "else:\n",
    "    SVM_cla = pickle.load(open(\"Support_Vector_Machine.sav\", 'rb'))\n",
    "print(calc_acc(SVM_cla.predict(X_test),Y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "if(preprocess):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train,Y_train)\n",
    "else:\n",
    "    model = pickle.load(open(\"LogisticRegression.sav\", 'rb'))\n",
    "print(calc_acc(model.predict(X_test),Y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting the size of area of contours"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if(preprocess):\n",
    "    X_c = []\n",
    "    Y_c = []\n",
    "\n",
    "    for file in tqdm(par):\n",
    "        img = cv2.imread(os.getcwd()+\"/data/train/Parasitized/{}\".format(file))\n",
    "        X_c.append(getContours(img))\n",
    "        Y_c.append(1)\n",
    "\n",
    "    for file in tqdm(uni):\n",
    "        img = cv2.imread(os.getcwd()+\"/data/train/Uninfected/{}\".format(file))\n",
    "        X_c.append(getContours(img))\n",
    "        Y_c.append(0)\n",
    "    X_c = np.asarray(X_c)\n",
    "    Y_c = np.asarray(Y_c)\n",
    "    np.save('contours.npy',X_c)\n",
    "    np.save('contours_labels.npy',Y_c)\n",
    "else:\n",
    "    X_c = np.load('contours.npy')\n",
    "    Y_c = np.load('contours_labels.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train,X_test,Y_train,Y_test = train_test_split(X_c,Y_c,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model Building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#KNN\n",
    "if(preprocess):\n",
    "    KNN = KNeighborsClassifier(n_neighbors = 193)\n",
    "    KNN.fit(X_train,Y_train)\n",
    "else:\n",
    "\n",
    "    \n",
    "print(calc_acc(KNN.predict(X_test),Y_test))\n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Support Vector Machine\n",
    "if(preprocess):\n",
    "    SVM_cla = SVC(gamma='scale')\n",
    "    SVM_cla.fit(X_train,Y_train)\n",
    "else:\n",
    "\n",
    "print(calc_acc(SVM_cla.predict(X_test),Y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Logistic Regression\n",
    "if(preprocess):\n",
    "    model = LogisticRegression()\n",
    "    model.fit(X_train,Y_train)\n",
    "else:\n",
    "\n",
    "    \n",
    "print(calc_acc(model.predict(X_test),Y_test))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adopting Deep Learning Apporaches"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from keras.layers import Dense, Conv2D, LeakyReLU, Input, Flatten,add, MaxPooling2D, BatchNormalization, Input, Dropout, add\n",
    "from keras.models import Sequential, Model\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import load_model\n",
    "from IPython.display import FileLink\n",
    "from keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_PATH = \"data/Parasite/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!rm -rf train val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.mkdir(\"train\")\n",
    "os.mkdir(\"train/0\")\n",
    "os.mkdir(\"train/1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "par = os.listdir(DATA_PATH+\"/train/Parasitized/\")\n",
    "uni = os.listdir(DATA_PATH+\"/train/Uninfected/\")\n",
    "uni.remove(\"Thumbs.db\")\n",
    "par.remove(\"Thumbs.db\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#making directories and storing the pre processed images\n",
    "for file in tqdm(par):\n",
    "    img = cv2.imread(DATA_PATH+\"/train/Parasitized/{}\".format(file))\n",
    "    img = cv2.resize(img,dsize=(130,130),interpolation=cv2.INTER_AREA)\n",
    "    cv2.imwrite(os.getcwd()+\"/train/1/{}\".format(file),img)\n",
    "for file in tqdm(uni):\n",
    "    img = cv2.imread(DATA_PATH+\"/train/Uninfected/{}\".format(file))\n",
    "    img = cv2.resize(img,dsize=(130,130),interpolation=cv2.INTER_AREA)\n",
    "    cv2.imwrite(os.getcwd()+\"/train/0/{}\".format(file),img)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Deep Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(filters=64,kernel_size=(5,5),activation='relu',input_shape=IMG_SIZE))\n",
    "model.add(Conv2D(filters=32,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Conv2D(filters=16,kernel_size=(5,5),activation='relu'))\n",
    "model.add(Conv2D(filters=8,kernel_size=(5,5),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Conv2D(filters=4,kernel_size=(3,3),activation='relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "model.add(BatchNormalization())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256,activation='relu'))\n",
    "model.add(Dropout(0.25))\n",
    "model.add(Dense(1,activation='sigmoid'))\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "traingen = ImageDataGenerator(rescale=1./255,rotation_range=15,validation_split=0.2)\n",
    "train = traingen.flow_from_directory('train/',shuffle=True,batch_size=64,color_mode='rgb',target_size=(130,130),class_mode='binary',subset='training')\n",
    "val = traingen.flow_from_directory('train/',shuffle=True,batch_size=32,color_mode='rgb',target_size=(130,130),class_mode='binary',subset='validation')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(monitor='accuracy', factor=0.1,patience=2, min_lr=0.0001)\n",
    "es = EarlyStopping(monitor='loss',min_delta=0.01,patience=4)\n",
    "history =model.fit_generator(train,epochs=epochs,steps_per_epoch=551,validation_data = val,callbacks=[lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Residual Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = Input(shape=IMG_SIZE)\n",
    "\n",
    "convb1_1 = Conv2D(filters=64,kernel_size=(3,3),activation='relu')(inputs)\n",
    "convb1_2 = Conv2D(filters=32,kernel_size=(5,5),activation='relu')(convb1_1)\n",
    "maxb1_1 = MaxPooling2D(pool_size=(2,2))(convb1_2)\n",
    "bn_1 = BatchNormalization()(maxb1_1)\n",
    "\n",
    "convb2_1 = Conv2D(filters=64,kernel_size=(3,3),activation='relu')(bn_1)\n",
    "convb2_2 = Conv2D(filters=32,kernel_size=(5,5),activation='relu')(convb2_1)\n",
    "maxb2_1 = MaxPooling2D(pool_size=(2,2))(convb2_2)\n",
    "bn_2 = BatchNormalization()(maxb2_1)\n",
    "\n",
    "convb3_1 = Conv2D(filters=64,kernel_size=(5,5),activation='relu')(bn_2)\n",
    "convb3_2 = Conv2D(filters=32,kernel_size=(3,3),activation='relu')(convb3_1)\n",
    "maxb3_1 = MaxPooling2D(pool_size=(2,2))(convb3_2)\n",
    "\n",
    "convb4_1 = Conv2D(filters=32,kernel_size=(3,3),activation='relu')(maxb3_1)\n",
    "maxb4_1 = MaxPooling2D(pool_size=(2,2))(convb3_1)\n",
    "flatten = Flatten()(maxb4_1)\n",
    "\n",
    "fc_1 = Dense(512,activation='relu')(flatten)\n",
    "dr_1 = Dropout(0.5)(fc_1)\n",
    "fc_2 = Dense(256,activation='relu')(dr_1)\n",
    "bn_3 = BatchNormalization()(fc_2)\n",
    "fc_3 = Dense(512,activation='relu')(bn_3)\n",
    "res_2 = add([fc_1,fc_3])\n",
    "dr_2 = Dropout(0.25)(res_2)\n",
    "fc_4 = Dense(256,activation='relu')(dr_2)\n",
    "res_2 = add([fc_2,fc_4])\n",
    "fc_5 = Dense(64,activation='relu')(res_2)\n",
    "predictions = Dense(1,activation='sigmoid')(fc_5)\n",
    "\n",
    "resmodel = Model(inputs=inputs,outputs=predictions)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = ReduceLROnPlateau(monitor='accuracy', factor=0.1,patience=2, min_lr=0.0001)\n",
    "es = EarlyStopping(monitor='loss',min_delta=0.01,patience=4)\n",
    "history =resmodel.fit_generator(train,epochs=epochs,steps_per_epoch=551,validation_data = val,callbacks=[lr])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(history.history['loss'])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Exractign test data\n",
    "testfiles = os.listdir(DATA_PATH+\"test/\")\n",
    "test = []\n",
    "for file in tqdm(testfiles):\n",
    "    img = cv2.imread(DATA_PATH+\"test/{}\".format(file))\n",
    "    img = cv2.resize(img,dsize=(130,130))\n",
    "    test.append(img)\n",
    "test = np.asarray(test)\n",
    "test = test.astype('float32')\n",
    "test /= 255.0\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#predicting values of the model \n",
    "#change model to resmodel for predicting residual networks output\n",
    "pred = model.predict(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#making the csv submission file\n",
    "from time import time\n",
    "fl = \"submission-{}.csv\".format(time())\n",
    "f = open(fl,\"w\")\n",
    "f.write(\"Name,Label\\n\")\n",
    "for i in range(0,len(testfiles)):\n",
    "    ans= 0\n",
    "    if(pred[i]>0.5):\n",
    "        ans = 1\n",
    "    f.write(\"{},{}\\n\".format(testfiles[i],ans))\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# the models are there in the folder given "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#the weights are there in submission_res_model_weights.h5 and model is in submission_res_model.h5\n",
    "filename = \"submission_res_model.h5\" # for loading the model directly\n",
    "model = keras.models.load_model(\"{}.h5\".format(filename))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
